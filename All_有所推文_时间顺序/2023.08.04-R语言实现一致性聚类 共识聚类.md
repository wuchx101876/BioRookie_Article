一致性/共识聚类（Consensus Clustering）严格来说并不是聚类方法。它是一种将多个聚类合并为一个更稳定聚类的技术。一致性聚类在**肿瘤分型**的研究中经常被使用。
>> "Altered Gene Expression along the Glycolysis–Cholesterol Synthesis Axis Is Associated with Outcome in Pancreatic Cancer"这篇论文是2020年发表在CLINICAL CANCER RESEARCH（2023,IF=11.5）上的，它就是利用了一致性聚的方法，有兴趣的可以看一下。 ![论文图A](https://files.mdnice.com/user/23696/e6f17a64-ebd6-4078-a458-0c55faa48e73.png)   
**这里主要讲一下用ConsensusClusterPlus包实现一致/共识聚类。**

## 一致性/共识聚类原理
##### 不需要的可以直接跳过，看后面用R语言实现过程。
#### 基本思想
- `重复运行聚类算法`： 对于给定的聚类数（k值），一致性聚类会重复运行聚类算法多次，每次在不同的数据子集和特征子集上进行抽样。
- `计算聚类一致性`： 对于每个聚类数，根据多次运行的聚类结果，计算样本被聚类到同一类别的频率。聚类一致性越高，表示该聚类数下的聚类结果越稳定。
- `选择最优聚类数`： 通过比较不同聚类数下的聚类一致性，可以选择最优的聚类数，从而确定最终的聚类结果。

#### 聚类方法
ConsensusClusterPlus包提供了三种无监督聚类方式，分别是`Hierarchical Clustering (层次聚类 - hc)、Partitioning Around Medoids (基于中心点的划分 - pam)、K-means (K均值聚类 - km)`
- `hc`：层次聚类是一种自底向上或自顶向下的聚类方法。在层次聚类中，每个样本开始都被视为一个单独的簇，然后逐步合并或分割簇，直到形成一个完整的聚类树（树状图）。
- `pam`：基于中心点的划分是一种聚类算法，与K-means相似，但它使用的中心点不是聚类的均值（mean），而是选择样本本身作为中心点，称为medoid。在pam中，每个簇都由一个代表样本（medoid）来代表。算法的目标是最小化每个样本到其所属簇中心的距离之和。
- `km`：K均值聚类是一种常见的聚类算法，它将数据样本划分成K个簇，其中K是预先指定的聚类数。K-means的基本思想是随机选择K个初始中心点，然后迭代地将样本分配到最近的中心点，并更新中心点的位置，直到达到收敛条件。

这三种聚类方法在不同的数据和应用场景下都有各自的优缺点。**可以都使用一下，看哪个效果最好。**

## R实现一致性聚类
#### 数据准备
使用的是之前下载的BRCA样本，做完GSVA富集得分之后的矩阵。关于样本获取和GSVA富集可以看一下之前的内容。
> [KEGG/GO/GSEA/GSVA富集分析（合集）](https://mp.weixin.qq.com/s?__biz=Mzg2NjYzNjQ4Ng==&mid=2247486146&idx=1&sn=ff99a883f5a8c811e32909ee3fde930c&chksm=ce468d6bf931047d168b51cdb9b0aacffbce1b0dc83c3c5bd28658a36bbfc1a017d604d122c6&token=703636547&lang=zh_CN#rd)

也可以使用已经做好的数据，直接来用。

百度云链接：https://pan.baidu.com/s/1mjfSQIwggDUP3MD9poOiBg  提取码：1bcq

```r
#包没有安装的可以先安装一下
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("ConsensusClusterPlus")

library(data.table) #数据读取使用
library(dplyr) #数据处理使用
library(ConsensusClusterPlus) #聚类使用

gsva_result <- fread("./ConsensusClusterPlus/BRCA_GSVA_SCORE.txt",data.table = F)
rownames(gsva_result) <- gsva_result$V1
gsva_result <- as.matrix(gsva_result[,-1]) #聚类输入需要是matri
```
数据一共50行，1039列。每一行都是一个通路（hallmark基因集通路），每一列都是一个肿瘤样本。

![聚类数据](https://files.mdnice.com/user/23696/b3d2ea5d-5a5f-4dde-8455-b71c4d665088.png)
#### 聚类
```r
maxK <-  6 # 选一个K值进行尝试
brca_result_km <-  ConsensusClusterPlus(gsva_result,
                                         maxK = maxK,
                                         reps = 1000,              # 抽样次数(一般1000或更多)
                                         pItem = 0.8,              # 抽样比例
                                         pFeature = 1,
                                         clusterAlg = "km",         # 聚类方法
                                         distance="euclidean",       # 距离计算方法
                                         title="./ConsensusClusterPlus/consensus_result/", # 结果保存路径
                                         innerLinkage="complete",  # 默认的方法是"average"
                                         plot="pdf",              # 结果保存形式
                                         seed = 123)               

saveRDS(brca_result_km,file = "./ConsensusClusterPlus/consensus_result/brca_result_km.rds") 
```
- 聚类方法可以选择：`'km', 'hc', 'pam'。`
- 距离计算方法也有多种选择，`'pearson', 'spearman', 'euclidean', 'binary', 'maximum', 'canberra', 'minkowski"。`

#### 类别选择
1、一致性矩阵生成的热图，此图也可以使用聚类结果进行重新绘制。

![](https://files.mdnice.com/user/23696/c8aeb1b0-9708-4163-ad34-7734a996c379.png)

2、累积分布函数（consensus cumulative distribution function，consensus CDF）。


![](https://files.mdnice.com/user/23696/93d4fe65-5464-41c6-9a52-c457cc891a78.png)

3、Tracking plot
这个图展示了在不同的 k 的情况下，样本所属的类的变化。
![](https://files.mdnice.com/user/23696/98f749a9-98c4-4e34-bbbe-ea5467886306.png)
通常结合这三张图可以帮助评估最合适的k值，尽量保证CDF分布更平缓值更高，且CDF曲线下面积提升相对更大的结果（拐点法）。例如在本示例中，考虑到样本的数量选择2或者4都是可以的，类别的选择不一定要遵守这个方法，可以根据自己的研究不同选择其它最优k值标准。

4、计算聚类一致性 (cluster-consensus，CLC) 和样品一致性 (item-consensus，IC)
```r
icl <- calcICL(brca_result_km, title = "./ConsensusClusterPlus/consensus_result/",plot = "png")
```
![](https://files.mdnice.com/user/23696/71178ad6-1d59-4ff4-914b-e42b256ce4c0.png)

这两个值也可以对选择类别起到参考作用

5、通过PCA自动计算最适分类。
通过比较不同K值下的PAC值，可以帮助确定最优的聚类数，从而得到相对稳定的聚类结果。
```r
Kvec = 2:6
x1 = 0.1; x2 = 0.9 
PAC = rep(NA,length(Kvec))
names(PAC) = paste("K=",Kvec,sep="")
for(i in Kvec){
  M = brca_result_km[[i]]$consensusMatrix
  Fn = ecdf(M[lower.tri(M)])
  PAC[i-1] = Fn(x2) - Fn(x1)
}
optK = Kvec[which.min(PAC)]
optK
```
- x1 = 0.1; x2 = 0.9：定义了两个数值x1和x2，用于计算PAC值。x1和x2分别代表一致性矩阵中的分位数值，用于定义分区的阈值。

![PCA计算分类结果](https://files.mdnice.com/user/23696/ed5f53e3-ac97-492a-b74d-b77bc0f6ae91.png)

##### 这里我们最终决定选择2类作为分类类别。
#### 数据保存
```r
class_result <- as.data.frame(brca_result_km[[2]]$consensusClass)
class_result$sample <- rownames(class_result)
colnames(class_result) <- c("class","sample")
table(class_result$class)
fwrite(class_result,"./ConsensusClusterPlus/consensus_result/class_result.txt")
```
![2类样本分布](https://files.mdnice.com/user/23696/46959fdf-2190-4e0a-846e-102d98fbd30a.png)

class1有538个样本，class2有501个样本。

##### 后面将以这两个类别为基础绘制生存曲线和其它分析，因为做的时候是随便找的数据以演示为主，emmmm，所以后续分析有没有差异就不一定了。
