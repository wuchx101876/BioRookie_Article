>>**公司测RNAseq数据，如果需要他跑流程分析，一个样本要增加150~200元**，学会下面这个流程，就可以帮老板把这个钱省下来啦（其实更重要得是，公司跑流程并不能提高个性化分析）。后面来分享一下原始RNA-seq测序数据的处理全流程，从测序公司拿到的原始fastq数据，到表达矩阵、差异分析以及富集分析。**今天先分享到表达矩阵的流程，主要在Linux系统上操作。**

## RNA-Seq数据处理流程

##### 质量控制（Quality Control，QC）：

- 目的： **评估测序数据的质量，检测潜在问题**。
- 步骤： 使用工具（如 `FastQC`）分析测序数据，检查读长分布、质量分布、GC含量、过度重复、接头含量等。

##### 数据预处理：
- 目的： **去除低质量 reads、去除接头、进行质量修剪**。
- 步骤： 使用工具（如 `fastp 或 Trimmomatic`）对原始测序数据进行预处理，提高后续分析的准确性。

##### 比对（Alignment）：
- 目的： **将测序 reads 映射到参考基因组上**。
- 步骤： 使用比对工具（如 `HISAT2、STAR、TopHat`）进行比对。生成 SAM/BAM 文件，其中包含每个 read 的映射位置。

##### 排序和索引：
- 目的： **提高数据的检索速度**。
- 步骤： 使用工具（如 `samtools`）对比对后的 BAM 文件进行排序，并为 BAM 文件创建索引。
##### 计数：
- 目的： **统计每个基因的 reads 数量，用于后续表达量分析**。
- 步骤： 使用工具（如 `featureCounts 或 HTSeq`）进行基因计数。生成一个表达矩阵，描述每个样本中每个基因的 reads 数量。
##### 表达量分析：
- 目的： **研究基因的表达水平，找到差异表达基因**。
- 步骤： 使用差异表达分析工具（如 `DESeq2、edgeR、limma`）进行统计分析，识别在不同条件下表达水平显著差异的基因。

##### 功能注释：
- 目的： **对差异表达基因进行生物学功能的注释**。
- 步骤： 做（`KEGG、GO、GSEA、GSEVA`）功能富集分析，了解差异表达基因的生物学过程、分子功能和细胞组分。

##### 可视化和解释：

- 目的：**将分析结果可视化，提高对实验结果的理解**。
- 步骤：使用图形工具（`如 R 中的 ggplot2、pheatmap`等）绘制差异表达基因的热图、散点图、火山图等，帮助解释实验结果。

## 运行实现

####  创建虚拟环境
在Linux上创建一个全新的虚拟环境来进行原始数据得分析，可以避免一些冲突和报错。
```sh
# 创建名为RNA-seq的虚拟环境
conda create --name RNA-seq
# 激活虚拟环境
conda activate RNA-seq
```

#### 安装所需的软件
有些步骤也可以使用别的软件（比对、计算count值等），但感觉这个流程就挺顺畅的。
```
# 质控
conda install -c bioconda fastqc
# 预处理
conda install -c bioconda fastp
# 比对
conda install -c bioconda hisat2
# 将sam文件转成bam文件
conda install -c bioconda samtools
# 计算count值
conda install -c bioconda subread
```

#### 质控信息
查看测序数据的质量信息，看一下数据测得质量怎么样
```r.fastq文件
# 生成质量信息，*.fastq表示匹配所有.fastq文件
fastqc ./*.fastq -o ./
```

![fastqc报告](https://files.mdnice.com/user/23696/a73d4502-a665-4e72-baee-7afea740a754.png)


#### 数据预处理
去除低质量 reads、去除接头、进行质量修剪等，可以根据需要进行参数调整，默认也可以
```
fastp -i raw_data_R1.fastq -I raw_data_R2.fastq -o cleaned_R1.fastq -O cleaned_R2.fastq -h fastp_report.html
```

![fastp过滤后的报告](https://files.mdnice.com/user/23696/80272aee-f0cb-4c47-ae22-85b959262feb.png)

质控之后，可以再查看一下质量信息做对比，当然这不是必须的，感兴趣的可以自己看。

#### 比对到参考基因组
将序列比对到参考基因组上，先下载参考基因组，目前常用的是hg38，**这个跟后续将count值转成tpm/fpkm值有关。具体可以看之前的推文**。

> - [R语言实现counts值到FPKM值和TPM值的转换，内置参考基因组基因长度](https://mp.weixin.qq.com/s?__biz=Mzg2NjYzNjQ4Ng==&mid=2247487398&idx=1&sn=396a3d4341a1fed2b1272fb1d44b21ae&chksm=ce46880ff93101190cc488e1baecab93cbd04d6cf032070bec180c720aeff5f3f4aa4eb5a60f&token=161811757&lang=zh_CN#rd)

``` bash
# 下载参考基因组
wget https://genome-idx.s3.amazonaws.com/hisat/grch38_genome.tar.gz
# 解压
tar -zxvf grch38_genome.tar.gz
```

![解压后的参考基因组](https://files.mdnice.com/user/23696/3178712c-0279-49e7-b877-ce1464a2fc2c.png)


```
# 比对
hisat2 -p 8 -x ./grch38/genome -1 ./cleaned_R1.fastq -2 ./cleaned_R2.fastq -S ./cleaned_data.sam
```
- `-p`:  **线程数目**
- `-x`: 基因组索引前缀。**下载的基因组索引为多个文件，索引前缀到genome为止**。
- `-1/-2`: fastq输入文件。当输入为单端测序时使用-U 指定输入。
- `-S`: 输出sam文件路径。


#### 排序和索引
将sam文件转成bam文件并排序，**这样做的好处是减少数据占用空间，提高速度**。这里我没有建立索引（因为数据比较少且比较小）如果数据量大可以建立索引，后续分析会更快。

```
# sam文件转成bam文件并排序
samtools view -bS cleaned_data.sam | samtools sort -o cleaned_data_sorted.bam
```
- `-b`: 将 SAM 文件转换为 BAM 格式。
- `-S`: 指定输入文件为 SAM 格式。

#### 表达量分析
这里需要下载hg38基因组的注释信息，链接：**https://www.gencodegenes.org/human/**

![gh38参考基因组](https://files.mdnice.com/user/23696/0f5cd60c-2bc7-4dc7-a004-b9786af0d029.png)

```
featureCounts -p -B -C -T 8 -a ./gencode.v44.annotation.gtf.gz -o data_counts.txt cleaned_data_sorted.bam
```
- `-p`: **只能用在paired-end的情况中，会统计fragment而不统计read**
- `-B`: 在-p选择的条件下，只有两端read都比对上的fragment才会被统计
- `-C`: 如果-C被设置，那融合的fragment（比对到不同染色体上的fragment）就不会被计数，这个只有在-p被设置的条件下使用
- `-T`: **线程数目，1~32**
- `-a`: 基因组注释gtf文件，支持Gzipped文件格式

##### 表达值结果

![表达值结果](https://files.mdnice.com/user/23696/bbe877cb-624b-44b5-a976-b64f27947c71.png)

一共七列，分别是`基因id`，`染色体`，`起始位点`，`终止位点`，`链的信息（正链或负链）`，`长度`，`count值`。

>> 这里只列举了这些软件的**部分参数**，具体参数可以查看他们的具体文档，**下面分别是用到的五个软件的详细文档**。
>> - https://wiki.rc.usf.edu/index.php/FastQC
>> - https://github.com/OpenGene/fastp
>> - https://daehwankimlab.github.io/hisat2/manual/
>> - https://www.htslib.org/doc/samtools.html
>> - https://subread.sourceforge.net/SubreadUsersGuide.pdf


#### 以上就是原始数据的处理流程，**虽然差异分析和富集分析之前更新过（可以在前面的推文中找到）**，不过后面按照这个下来的步骤重新整理和更新一下代码（**避免时间长了，软件更新，代码报错**）。